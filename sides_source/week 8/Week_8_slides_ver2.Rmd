---
title: "Advanced quantitative methods øvelsestime uge 8"
author: "Rasmus Klokker"
output:
  xaringan::moon_reader:
    self_contained: true
    keep_tex: true
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: center, middle


```{r setup, include=FALSE}
library(magick)

library(ggplot2)

library(dplyr)

library(xaringanExtra)

library(tidyr)

library(furniture)

library(flextable)

library(modelsummary)
library(haven)
library(texreg)

library(estimatr)

library(purrr)




options(htmltools.dir.version = FALSE)

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message=FALSE, dpi=300)

crop <- function(im, left = 0, top = 0, right = 0, bottom = 0) {
  d <- dim(im[[1]]); w <- d[2]; h <- d[3]
  image_crop(im, glue::glue("{w-left-right}x{h-top-bottom}+{left}+{top}"))
}


theme_set(theme_minimal(base_size = 16,base_family = "serif")+ theme(axis.line = element_line(color='black'),
    plot.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank()))

xaringanExtra::use_panelset()

```


```{css, echo=FALSE}
.strike {
  text-decoration: line-through
}
```


```{css, echo=FALSE}
.watch-out {
  background-color: lightpink;
  border: 3px solid red;
  font-weight: bold;
}

.scroll-output {
  height: 90%;
  overflow-y: scroll;
}

.scroll-output-2 {
   overflow: scroll !important;
   white-space: nowrap;
   width: 100%;
   height: 100%;
}

.scroll-box-14 {
  height:14em;
  overflow-y: scroll;
}

.scroll-box-14-2 {
  height:14em;
  width:14em;
  overflow-y: scroll;
  overflow-x: scroll;
}

.pull-left-1 {
  float: left;
  width: 36%;
}
.pull-right-2 {
  float: right;
  width: 60%;
}

.right-column{
  padding-top: 0;
}

.center2 {
  margin: 0;
  position: absolute;
  top: 50%;
  -ms-transform: translate(-50%, -50%);
  transform: translate(-50%, -50%);
}

```



```{r get_data}

# Dat_citi_rights <- download_fh(verbose = FALSE) %>% # Download Freedom House data for all countries since 1972,
#    rename(country = fh_country, # rename country ID,
#           citizen_rights = fh_total_reversed, # rename Citizenship rights indicator,
#           date = year)

```




#Spørgsmål til undervisningen?


---

#multipel regression

Nu kan vi kontrollere for confounders!!

---

#omitted variable bias

Hvad sker der når vi ikke kontrollerer for confounders?

*Omitted variable bias*..Det er hvad der sker!! 


```{r, out.width="600px", out.height="400px"}
knitr::include_graphics("6z3g0q.jpg")
```


---

Når der er variable som er blevet "udeladt" fra vores regression, som skulle have været kontrolleret for, så får vi "omitted variable bias"(OVB)

Omitted variable bias minder om selection bias i den forstand, at vi "får for meget med" når vi udelader variable, vi ikke skulle have udeladt. 

I forhold til OVB består bias i at vi også får 

$sammenhæng~mellem~confounder~og~treatment \times samenhæng~mellem~confounder~og~outcome$ 

med i købet når vi får en regressionskoefficient. 

Hvis vi har OVB bliver vores regressionskoeffiecient derfor:


$\scriptsize \beta_{treatment}=Kausal~effekt_{treatment}+\underbrace{(sammenhæng~mellem~confounder~og~treatment \times samenhæng~mellem~confounder~og~outcome)}_\textrm{omitted variable bias}$



Det vi var interesserede i at få var jo $Kausal~effekt_{treatment}$, men indtil vi har kontrolleret for alle confounders så kommer det ikke til at ske.


---

#OVB eksempel

Lad os tage en tur tilbage til ESS og til variablen "psppipla"(political efficacy). Her vil vi gerne se på effekten af udannelsesniveau("eduyrs") på political efficacy

```{r load-ess, echo=TRUE}

ESS <- read_spss("C:/Users/B059064/Desktop/PHD/teaching/advanced stats/ESS9e03_1.sav") %>%
  filter(cntry == "DK") %>% # Keep only the Danish data,
  # Keep only a minimum set of variables we need today,
  select(idno, pspwght, gndr, eduyrs, agea, 
         psppsgva, trstlgl, trstplc, pdwrk,health, psppipla) %>%
  drop_na() # Delete cases with missing values.

ESS <- ESS %>% mutate(
  psppsgva = zap_labels(psppsgva), # Make numeric
  eduyrs = case_when( # Censor years of education at 9 & 21 years.
    eduyrs > 21 ~ 21,
    eduyrs < 9 ~ 9,
    TRUE ~ as.numeric(eduyrs)),
  gndr = as_factor(gndr)) # Make factor




```


---

```{r ESS-ex, echo=TRUE, results='asis'}

mod1 <- lm(scale(psppipla) ~ scale(eduyrs), data = ESS)



htmlreg(list(mod1))

```

---

Men hvad nu, hvis vi troede at alder var en confounder? 

$0.216=kausal~effekt+(sammenhæng~mellem~alder~og~udd. \times sammenhæng~mellem~alder~og~pol.~eff.)$

Hvad hvis troede at korrelationen mellem alder og udannelsesniveau var dobbelt så stor som korrelationen mellem uddannelsesniveau og political efficacy? Og hvad hvis korrelationen mellem alder og political efficacy var lige så stor? 

$\begin{aligned} 0.216=kausal~effekt+0.216 \times 2 \times 0.216 \times 2\\=\\0.216=kausal~effekt+0.432 \times 0.432 \end{aligned}$

Hvor stor, eller lille, ville den kausale effekt så være?

---

Her er det rigtig heldigt for mig, at R også kan løse ligninger, så vi kan finde $kausal~effekt$ 

```{r eq-solve, echo=TRUE}

f <- function(x){
  x+0.432*0.432 - 0.216
}



sol <- uniroot(f, interval = c(-1e+08, 1e+08))

sol$root


```
Så bliver effekten af uddannelsesniveau næsten 10 gange mindre! 


---

Men hvor stærk skal vores confounder være, før effekten helt forsvinder?

```{r plotly-contour, out.width="1000px", out.height="600px"}

grid <- expand.grid(seq(-.8,.8,.1), seq(-.8,.8,.1))

sens.loop <- lapply(1:nrow(grid), function(x){
  
  #cat(paste("processing row", x))
  
  #x <- 1
  
  f <- function(y){
    y+grid[x,1]*grid[x,2] - -0.216
  }
  
  

  
  sol <- uniroot(f, interval = c(-1e+08, 1e+08))
  
  #cat(paste(sol$root, "cor conf-treat", grid[x,1], "cor conf-outcome", grid[x,2], "\n"))
  
  df <- data.frame(true_effect=sol$root, confounder_treatment_correlation=grid[x,1], confounder_outcome_correlation=grid[x,2])
  
  
  return(df)
})

sens.loop.df <- do.call("rbind", sens.loop)



p <- ggplot(sens.loop.df, aes(confounder_treatment_correlation, confounder_outcome_correlation, z = true_effect, colour=stat(level))) +
  geom_contour(breaks=c(seq(-.8,-.1,.2),-.01,0,.01,seq(.1,.8,by=.2)))+scale_colour_gradient2(low = "yellow", 
                                                                                            mid="black", high = "red", na.value = 'blue',
                                                                                            limits=c(-.1,.1))

# p <- ggplot(sens.loop.df, aes(conf_treat_cor, conf_outcome_cor, z = true_eff, colour=stat(level))) +
#   geom_contour(bins=50)+scale_colour_gradient2(low = "yellow",mid="black", high = "red", na.value = 'blue',limits=c(-.1,.1))+
#   scale_x_continuous(breaks = seq(-.8,.8,.1)) +
#   scale_y_continuous(breaks = seq(-.8,.8,.1))


library(plotly)

ggplotly(p)


```


---

#OVB opsummering

Fortæller os meget præcist, hvorfor vores regressionskoeffiecient ændrer sig som den gør når vi kontrollerer for en confounder(hvis altså vi ved hvad $kausal~effekt$, $sammenhæng~mellem~counfounder~og~treatment$ og $sammenhæng~mellem~counfounder~og~outcome$ er)

kan også bruges til at sige noget om, hvad der ville ske med vores regressionskoefficient, hvis vi en confounder var så og så stærkt korreleret med vores treatment og vores outcome.

---

# Hvad sker der når man kontrollerer?


#Frisch-waugh-lovell

Når man kontrollerer for ting i en regression, er ideen at vi gerne vil holde alt andet en X konstant. Det vil sige, vi vil gerne se hvad der sker med Y, når vi ændrer på X og _intet andet_. 

Resten af verden skal stå stille mens kun X bevæger sig!

---

For at sørge for at alt andet end x "står stille" kan vi gøre brug af residualerne. 

Residualerne er, oftest, den variation i Y som _ikke_ kan forklares af vores uafhængige variable.

Med andre ord er residualerne et slags mål for alt det som foregår i Y, som vores uafhængige variable ikke har noget at gøre med eller har nogen indflydelse på. 

På den måde kan vi sige at residualerne, $\widetilde{Y}$ er den "del" af Y som ikke har nogen sammenhæng med vores uafhængige variable. 

```{tikz, fig.ext = 'png', fig.width=10, out.width="700px", out.height="300px"}


\begin{tikzpicture}[x=30in, y=10in]
\node (v0) at (0.236,-0.348) {X};
\node (v1) at (0.458,-0.341) {Y};
\node (v2) at (0.458,-0.173) {\~{Y}};
\draw [<->] (v2) edge (v1);
\draw [->] (v0) edge (v1);
\end{tikzpicture}

```


---

Hvis vi nu anvender den logik på vores X og confounders, så kan vi sige at Residualerne for X, $\widetilde{X}$,  er X som er "renset" for confounders.

```{tikz, fig.ext = 'png', fig.width=10, out.width="700px", out.height="300px"}
\begin{tikzpicture}[x=30in, y=10in]
\node (v0) at (0.463,-0.239) {confounder};
\node (v1) at (0.347,-0.473) {X};
\node (v2) at (0.569,-0.471) {Y};
\node (v3) at (0.347,-0.55) {\~{X}};
\draw [->] (v0) edge (v1);
\draw [->] (v1) edge (v2);
\draw [->] (v0) edge (v2);
\draw [->] (v3) edge (v2);
\end{tikzpicture}
```


---

Hvis vi så også har residualerne fra $\widetilde{Y}$, så har vi fuldstændigt afskåret vores confounder fra fra både X og Y 

```{tikz, fig.ext = 'png', fig.width=10, out.width="700px", out.height="300px"}
\begin{tikzpicture}[x=30in, y=10in]
\node (v0) at (0.463,-0.239) {confounder};
\node (v1) at (0.347,-0.473) {\~{X}};
\node (v2) at (0.569,-0.471) {\~{Y}};
\draw [->] (v1) edge (v2);
\end{tikzpicture}
```


---

# Hvordan sker det i praksis?

Alt det her er heldigvis nemt at gøre i R :) 

Her prøver vi at se på effekten af at have et haft et betalt arbejde i det sidste stykke tid på ens tillid til det juridiske system. 

Vi forestiller os, at tilliden til det juridiske system måske lider et knæk når man skal stille bekendtskab med det kafkaske mareridt vi kalder dagpenge-systemet.

---

Samtidig er vi dog bekymrede for, om uddannelsesniveau kan være en confounder. 

Måske er der både højere sandsynlighed for at have et betalt arbejde og for at have tillid til det juridiske system, hvis man har en højere uddannelse?

```{tikz, fig.ext = 'png', fig.width=10, out.width="700px", out.height="300px"}


\begin{tikzpicture}[x=30in, y=10in]
\node (v0) at (0.463,-0.239) {udd. niveau};
\node (v1) at (0.347,-0.473) {betalt arbejde};
\node (v2) at (0.569,-0.471) {tillid til jur};
\draw [->] (v0) edge (v1);
\draw [->] (v1) edge (v2);
\draw [->] (v0) edge (v2);
\end{tikzpicture}
```



---

Først indlæser vi vores data

```{r load-ess1, echo=TRUE, eval=FALSE}

ESS <- read_spss("C:/Users/B059064/Desktop/PHD/teaching/advanced stats/ESS9e03_1.sav") %>%
  filter(cntry == "DK") %>% # Keep only the Danish data,
  # Keep only a minimum set of variables we need today,
  select(idno, pspwght, gndr, eduyrs, agea, 
         psppsgva, trstlgl, trstplc, pdwrk,health) %>%
  drop_na() # Delete cases with missing values.

ESS <- ESS %>% mutate(
  psppsgva = zap_labels(psppsgva), # Make numeric
  eduyrs = case_when( # Censor years of education at 9 & 21 years.
    eduyrs > 21 ~ 21,
    eduyrs < 9 ~ 9,
    TRUE ~ as.numeric(eduyrs)),
  gndr = as_factor(gndr)) # Make factor


```

---

Og så kører vi den første regression

```{r first reg, echo=TRUE}


mod0 <- lm(trstlgl ~ pdwrk, data = ESS)

mod1 <- lm(trstlgl ~ eduyrs, data = ESS)




```

---


Nu kan vi på en måde "splitte" _trstlgl_ op i to:

1. Den del af variansen i _trstlgl_ som kan forklares af "eduyrs", hvilket er de forudsagte værdier, $\widehat{trslgl}$ 

Og

2. Den del af variansen som ikke kan forklares af "eduyrs", nemlig residualerne, $\widetilde{trstlgl}$.

Med andre ord har vi den del af _trstlgl_ som udelukkende har "at gøre" med "eduyrs", $\widehat{trslgl}$ , og den del af _trstlgl_ som intet har at gøre med "eduyrs", $\widetilde{trstlgl}$.


```{r get res and fit Y, echo=TRUE}


#vi får residualerne

trst.res <- mod1 %>% pluck(residuals)

#vi  får de forudsagte værdier

trst.fitted <- mod1 %>% pluck(fitted.values)

# vi laver variable der indeholder residualerne og de forudsagte værdier

ESS <- ESS %>% mutate(trst_res = trst.res, trst_fitted= trst.fitted)




```


---

```{r res-plots, out.width="800px", out.height="500px"}

p <- ggplot(data=ESS, aes(x=pdwrk,y=trstlgl))
p <- p+geom_jitter()
p0 <- p+ggtitle(label="association between pdwrk and trstlgl")


p <- ggplot(data=ESS, aes(x=pdwrk,y=trst_res))
p <- p+geom_jitter()
p1 <- p+ggtitle(label="association between pdwrk and trstlgl residuals")


p <- ggplot(data=ESS, aes(x=pdwrk,y=trst_fitted))
p <- p+geom_jitter()
p2 <- p+ggtitle(label="association between pdwrk and trstlgl predicted values")


library(patchwork)

p0/p1/p2

```


---

Vi gør det samme med den uafhængige variabel

```{r get res Y, echo=TRUE}

mod2 <- lm(pdwrk ~ eduyrs, data = ESS)



#edu.res <- (ESS %>%  pull(eduyrs)) - (mod2 %>% pluck(fitted.values))

pdwrk.res <- mod2 %>% pluck(residuals)

pdwrk.fitted <- mod2 %>% pluck(fitted.values)


ESS <- ESS %>% mutate(pdwrk_res = pdwrk.res, pdwrk_fitted= pdwrk.fitted)




```


---

```{r res-plots2, out.width="800px", out.height="500px"}

p <- ggplot(data=ESS, aes(x=pdwrk,y=trstlgl))
p <- p+geom_jitter()
p0 <- p+ggtitle(label="association between pwrk and trstlgl")


p <- ggplot(data=ESS, aes(x=pdwrk_res,y=trstlgl))
p <- p+geom_jitter()
p1 <- p+ggtitle(label="association between pdwrk residuals and trstlgl")


p <- ggplot(data=ESS, aes(x=pdwrk_fitted,y=trstlgl))
p <- p+geom_jitter()
p2 <- p+ggtitle(label="association between pdwrk predicted values and trstlgl")


library(patchwork)

p0/p1/p2

```

---

Når vi sætter det hele sammen ser det altså sådan her ud



```{r res-plots3, out.width="800px", out.height="500px"}

p <- ggplot(data=ESS, aes(x=pdwrk,y=trstlgl))
p <- p+geom_jitter()
p <- p+geom_smooth(method="lm")
p0 <- p+ggtitle(label="association between pwrk and trstlgl")


p <- ggplot(data=ESS, aes(x=pdwrk_res,y=trst_res))
p <- p+geom_jitter()
p <- p+geom_smooth(method="lm")
p1 <- p+ggtitle(label="association between pdwrk residuals and trstlgl residuals")


p <- ggplot(data=ESS, aes(x=pdwrk_fitted,y=trst_fitted))
p <- p+geom_jitter()
p <- p+geom_smooth(method="lm")
p2 <- p+ggtitle(label="association between pdwrk predicted values and trstlgl predicted values")


library(patchwork)

p0/p1/p2

```

---

Og så bruger vi vores residualer som variable

```{r FWL in action, echo=TRUE, results='asis'}

ESS <- ESS %>% mutate(trst_res = trst.res, pdwrk_res= pdwrk.res)


mod.res <- lm(trst_res ~ pdwrk_res, data = ESS)

mod.ctrl <- lm(trstlgl ~ pdwrk+eduyrs, data = ESS)




htmlreg(list(mod0,mod.res,mod.ctrl))


```


---


# Øvelse

I den her øvelse skal vi, ligesom før, se på sammenhængen mellem "pdwrk" og "trstlgl", når vi kontrollerer for "eduyrs". 

Men vi er bekymrede for, at folk med dårligt helbred måske i lavere grad har et betalt arbejde samtidig med at de måske også har stiftet bekendtskab med de mere uheldigere dele af bureakratiet i sundhedssystemet og derfor har mindre tillid til det juridiske system.

Hvis det er tilfældet, bliver vi nødt til også at kontrollere for helbred

```{tikz, fig.ext = 'png', fig.width=10, out.width="700px", out.height="300px"}
\begin{tikzpicture}[x=30in, y=10in]
\node (v0) at (0.173,-0.378) {betalt arbejde};
\node (v1) at (0.458,-0.374) {tillid til juridisk system};
\node (v2) at (0.323,-0.177) {helbred};
\node (v3) at (0.320,-0.0736) {uddannelsesniveau};
\draw [->] (v2) edge (v0);
\draw [->] (v2) edge (v1);
\draw [->] (v0) edge (v1);
\draw [->] (v3) .. controls (0.283,-0.143) and (0.234,-0.244) .. (v0);
\draw [->] (v3) edge (v1);
\end{tikzpicture}
```


---

#Del 1/4

I første del skal vi kontrollere for "eduyrs" på samme måde som vi lige har gjort. Du må godt copy-paste fra slides :) 

---

#Del 2/4

I næste del skal vi kontrollere for helbred

Her skal du/i

1) Køre en regression, hvor du bruger _residualerne_ for "trstlgl" fra Del 1 af øvelsen, som du lige har beregnet og forhåbentlig lavet til en variabel i datasættet, som den afhængige variabel og variablen "health" som den uafhængige variabel

2) Træk residualerne ud fra den model du kørte i 1) og lav en variabel i dit datasæt, som indeholder residualerne.

skip til næste slide for at se løsningen

---

```{r ex1, echo=TRUE}

mod3 <- lm(trst_res ~ health, data = ESS)



#edu.res <- (ESS %>%  pull(eduyrs)) - (mod2 %>% pluck(fitted.values))

trst.res <- mod3 %>% pluck(residuals)


ESS <- ESS %>% mutate(trst_res = trst.res)




```


---

#Del 3/4

Nu skal vi beregne residualerne for "pdwrk".

## Del 3.1

Ligesom før skal vi først kontrollere for "eduyrs", og ligesom før kan i bare copy-paste fra slides og lave en variabel i ESS med de residualer.

##Del 3.2

Nu skal vi så kontrollere for "health". Ligesom før skal du/i bruge de residualer du lige har beregnet, i Del 3.1, som afhængig variabel: 

1) Kør en regression, hvor du bruger _residualerne_ for "pdwrk", som du lige har beregnet og forhåbentlig lavet til en variabel i datasættet, som den afhængige variabel og variablen "health" som den uafhængige variabel

2) Træk residualerne ud fra den model du kørte i 1) og lav en variabel i dit datasæt, som indeholder residualerne.

skip til næste slide for at se løsningen

---


```{r ex2, echo=TRUE}

mod4 <- lm(pdwrk_res ~ health, data = ESS)



#edu.res <- (ESS %>%  pull(eduyrs)) - (mod2 %>% pluck(fitted.values))

pdwrk.res <- mod4 %>% pluck(residuals)


ESS <- ESS %>% mutate(pdwrk_res = pdwrk.res)




```

---

#Del 4/4

NU kan vi så se hvad der sker når vi både har kontrolleret for "health" og "eduyrs"!

1) kør en regression hvor du anvender residualerne for "trstlgl" som afhængig variabel og residualerne for "pdwrk" som uafhængig variabel. Gem modellen som objekt

2) kør en regression hvor du ikke kontrollerer for noget, dvs. "trstlgl" som afhængig variabel og "pdwrk" som uafhængig variabel, og ikke mere. Gem modellen som et objekt

3) Kør en regression som i 2), men hvor du kontrollerer for "eduyrs" og "health", Det vil sige "trstlgl" som afhængig variabel, og "pdwrk", "eduyrs" og "health" som uafhængige variable

4) Sammelign resultaterne fra de 3 regressioner, evt. i "screenreg". 

Skip til næste slide for at se løsningen

---


```{r FWL in action-ex, echo=TRUE}




mod.naive <- lm(trstlgl ~ pdwrk, data = ESS)

mod.res <- lm(trst_res ~ pdwrk_res, data = ESS)

mod.ctrl <- lm(trstlgl ~ pdwrk+eduyrs+health, data = ESS)




screenreg(list(mod.naive,mod.res,mod.ctrl), digits=4)


```


---



#fortolkning

Fortolkningen er af vores regressionskoefficient er heldigvis fuldstændig ligesom før. Nu kan vi dog tilføje en enkelt ting:

Nu kan vi sige, at vores regressionskoefficient angiver ændringen der sker i vores outcome, for en enhedsændring í vores treatment, _når vi kontrollerer for vores kontrol variable_

I vores eksempel kan således sige at regressionskoefficienten for "pdwrk" er ændringen i "trstlgl" når vi øger "pdwrk" med en enhed, _kontrolleret for "eduyrs" og "health_

---

## Kan vi fortolke vores kontrolvariable?

Når vi har kontrolleret for vores kontrolvariable, tror vi jo ikke der mere confounding på $X_1$. Men derfor kan vores kontrolvariable jo godt være udsat for confounding


```{tikz, fig.ext = 'png', fig.width=10, out.width="700px", out.height="300px"}


\begin{tikzpicture}[x=30in, y=10in]
\node (v0) at (0.236,-0.348) {$X_{1}$};
\node (v1) at (0.458,-0.341) {Y};
\node (v2) at (0.358,-0.173) {$X_{2}$};
\node (v3) at (0.500,-0.119) {$X_{3}$};
\draw [->] (v2) edge (v0);
\draw [->] (v2) edge (v1);
\draw [->] (v0) edge (v1);
\draw [->] (v3) edge (v2);
\draw [->] (v3) edge (v1);
\end{tikzpicture}
```





---

#gennemgang af øvelse

---

# Vi ses næste uge!!

## Office hours

16.2.08, mandag-torsdag 13-15

rhk@vive.dk

rhk@soc.ku.dk